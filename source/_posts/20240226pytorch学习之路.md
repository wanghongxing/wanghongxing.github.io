---
title: 20240226pytorch学习之路
date: 2024-02-26 09:20:34
---

pytorch学习之路

pytorch包含以下组件

torch: 一个像numpy 向量库

torch.autograd 自动微分库，支持所有微分向量运算

torch.jit 一个编译栈，从pytorch代码来创建可序列化、可以优化的模型

torch.nn 神经元网络库，设计之初保持了最大化灵活性，深度继承了求导库

torch.multiprocessing 多处理，在torch 向量访问处理器时使用了魔术化的内存共享。在数据加载和疯狂的训练模型的时候非常有用。

torch。utils 数据记在和其他功能



通常pytorch用作两个方面：

1、替代numpy来使用gpu

2、提供最大灵活性和速度的深度学习研究平台



动态神经元网络：使用磁带记录仪回放这种独特的方法来创建神经元网络。

pytorch使用反向模式自动微分技术，让我们经常零成本的改变网络行为；我们的灵感来自于这篇文章的几个研究报告。

这个技术不是pytorch独有的。这是目前为止最快速的实现。你可以为你疯狂的研究获得最快的速度和灵活性。



pytorch不是一个整体绑定到 c++框架的。他是深度集成到python中。你可以像使用numpy scipy scikit-learn一样自然的使用它。你可以写你自己全新神经元网络，使用你喜欢的库和包。我们的目标是不重复造轮子。

必要的经验

pytorch设计为只觉得、线性的思考、简单易用。当你执行一行代码，他被执行了。在现实世界中他不是异步视图。当你调试一行代码或者接收到错误信息和堆栈跟踪，理解他们是很直观的。堆栈调用之初你的代码在哪里被定义。我们希望你不要因为坏的堆栈调用、异步执行和不透明的执行引擎而花费时间调试你的代码。

快速和学习

pytorch有最小的框架成本。我们继承了加速库像intel MKL 和nvidia（cuDNN nccl)去最大化速度。最核心的，他核心的cpu gpu向量和神经元网络是成熟的并且经过多年测试的。

因此，pytorch是非常快的，无论执行小规模还是大规模的模型。

无痛扩展

## 安装

二进制，命令行通过conda 或者pip 安装 参照： https://pytorch.org/get-started/locally/

源代码安装

需要满足：python 3.8+；编译器全面支持C++17，像clang或者gcc（gcc 9.4.0或者最新）

强烈推荐安装conda环境。

如果想要编译cuda支持，从我们的支持矩阵里选择一个我们支持的版本[select a supported version of CUDA from our support matrix](https://pytorch.org/get-started/locally/)。然后安装nvidia cuda ,nvidia cuDNN v8.5 + ,CUDA兼容的编译器。

如果要禁用CUDA，设置环境变量 USE_CUDA=0 .其它有用的环境变量在setup.py中。

#### 安装依赖



#### Get the PyTorch Source

```
git clone --recursive https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
git submodule sync
git submodule update --init --recursive
```



通用

```
conda install cmake ninja
# Run this command from the PyTorch directory after cloning the source code using the “Get the PyTorch Source“ section below
pip install -r requirements.txt
```

**On Linux**

```
conda install intel::mkl-static intel::mkl-include
# CUDA only: Add LAPACK support for the GPU if needed
conda install -c pytorch magma-cuda110  # or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo

# (optional) If using torch.compile with inductor/triton, install the matching version of triton
# Run from the pytorch directory after cloning
make triton
```

**On MacOS**

```
# Add this package on intel x86 processor machines only
conda install intel::mkl-static intel::mkl-include
# Add these packages if torch.distributed is needed
conda install pkg-config libuv
```

**On Windows**

```
conda install intel::mkl-static intel::mkl-include
# Add these packages if torch.distributed is needed.
# Distributed package support on Windows is a prototype feature and is subject to changes.
conda install -c conda-forge libuv=1.39
```



#### Install PyTorch

**On macOS**

```
python3 setup.py develop
```